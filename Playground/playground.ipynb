{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECG Beat Detector Comparison\n",
    "## Important Variables\n",
    "Important variables used throughout the code can be changed here.\n",
    "- `segmentation_window_size`: every signal in a database is sliced into pieces of `segmentation_window_size` seconds to make the signals more comparable\n",
    "- `tolerance_window_size`: to determine wether a QRS complex was determined correctly a tolerance window of Â±`tolerance_window_size` milliseconds is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_window_size = 10 # in seconds, default is 10\n",
    "tolerance_window_size = 150 # in milliseconds, default is 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries & Start Engines\n",
    "Install all important libraries with pip apart from `matlab.engine` which has to be installed from the MATLAB root folder. You can find more information on instlaling the `matlab.engine` [here](https://de.mathworks.com/help/matlab/matlab_external/install-the-matlab-engine-for-python.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matlab.engine\n",
    "import numpy as np\n",
    "from cProfile import label\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n",
    "import pathlib\n",
    "from ecgdetectors import Detectors\n",
    "import sys\n",
    "import wfdb\n",
    "from wfdb import processing\n",
    "import pandas\n",
    "import os\n",
    "from detectors.visgraphdetector import VisGraphDetector\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "current_working_directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the `matlab.engine` to be able to execute MATLAB commands or functions from within Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng = matlab.engine.start_matlab()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Classes and Functions\n",
    "`Detector` class to store all values necessary for a detector. This can later be added to a list of `detectors`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detector():\n",
    "    def __init__(self, name, short_name, algorithm) -> None:\n",
    "        self.name = name\n",
    "        self.algorithm = algorithm\n",
    "        self.short_name = short_name\n",
    "    \n",
    "    def predicted_qrs_compelx(self, signal, fs):\n",
    "        return self.algorithm(signal, fs)\n",
    "\n",
    "    def name(self):\n",
    "        return self.name\n",
    "\n",
    "    def short_name(self):\n",
    "        return self.short_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An `Evaluation` gets a `RecordingSegment` or `Recording` described below and the functions `predicted_peaks`, `binary_classification`, and `score_calculation`. The function `calculate` returns the whole element including `predicted_peaks`, number of predicted peaks `pp`, true positives `tp`, false positives `fp`, false negatives `fn`, `sensitivity`, `positive_predictivity`, and the `f1_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation():\n",
    "    def __init__(self, RecordingSegment, Detector, predict_peaks, binary_classification, score_calculation) -> None:\n",
    "        self.RecordingSegment = RecordingSegment\n",
    "        self.Detector = Detector\n",
    "        self.predict_peaks = predict_peaks\n",
    "        self.binary_classification = binary_classification\n",
    "        self.score_calculation = score_calculation\n",
    "        self.predicted_peaks = None # predicted peaks as indexes\n",
    "        self.pp = self.tp = self.fp = self.fn = None # number of predicted peaks, true positives, false positives, false negatives respectively\n",
    "        self.sensitivity = self.positive_predictivity = self.f1_score = None\n",
    "    \n",
    "    def calculate(self):\n",
    "        self.predicted_peaks = self.predict_peaks(self.RecordingSegment,self.Detector)\n",
    "        self.pp, self.tp, self.fp, self.fn = self.binary_classification(self.RecordingSegment, self.predicted_peaks)\n",
    "        self.sensitivity, self.positive_predictivity, self.f1_score = self.score_calculation(self.tp, self.fp, self.fn)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Database` class to store all values necessary for a databse. This can later be added to a list of `databases`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Database():\n",
    "    def __init__(self, Name, Users, Fs) -> None:\n",
    "        self.Name = Name\n",
    "        self.Users = Users\n",
    "        self.Fs = Fs\n",
    "\n",
    "    def Name(self):\n",
    "        return self.Name\n",
    "\n",
    "    def Users(self):\n",
    "        return self.Users\n",
    "\n",
    "    def Fs(self):\n",
    "        return self.Fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each `Database` stores a list of `Users`. This `User` class stores important information about a user and a list to `Recordings` this user took. `User` can here also be used if a database stores arrythmia and sinus rythm signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class User():\n",
    "    def __init__(self, UserName,Recordings) -> None:\n",
    "        self.UserName = UserName\n",
    "        self.Recordings = Recordings\n",
    "\n",
    "    def UserName(self):\n",
    "        return self.UserName\n",
    "\n",
    "    def Recordings(self):\n",
    "        return self.Recordings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each `User` stores a list of `Recordings`. This `Recording` class stores important information about a recording and a list to `RecordingSegments` created from the signal in `Recording`. `Recording` stores the whole unsplit signal and list of actual QRS complexes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recording():\n",
    "    def __init__(self, RecordingName, RecordingSegments, WholeSignal, WholeActual_Qrs_Complex, Fs) -> None:\n",
    "        self.RecordingName = RecordingName\n",
    "        self.RecordingSegments = RecordingSegments\n",
    "        self.WholeSignal = WholeSignal\n",
    "        self.WholeActual_Qrs_Complex = WholeActual_Qrs_Complex\n",
    "        self.Fs = Fs\n",
    "\n",
    "    def RecordingName(self):\n",
    "        return self.RecordingName\n",
    "    \n",
    "    def RecordingSegments(self):\n",
    "        return self.RecordingSegments\n",
    "\n",
    "    def WholeSignal(self):\n",
    "        return self.WholeSignal\n",
    "    \n",
    "    def WholeActual_Qrs_Complex(self):\n",
    "        return self.WholeActual_Qrs_Complex\n",
    "\n",
    "    def Fs(self):\n",
    "        return self.Fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each `Recording` stores a list of `RecordingSegments`. The `RecordingSegment` class stores important information about a segment of a recording. The function `Evaluation` which takes a list of `detectors` and three functions as an input returns a list of `Evaluation` objects, one for each detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecordingSegment():\n",
    "    def __init__(self, Signal, Actual_Qrs_Complex, Fs) -> None:\n",
    "        self.Signal = Signal\n",
    "        self.Actual_Qrs_Complex = Actual_Qrs_Complex\n",
    "        self.Fs = Fs\n",
    "        self.Evaluations = []\n",
    "\n",
    "    def Signal(self):\n",
    "        return self.Signal\n",
    "\n",
    "    def Actual_Qrs_Complex(self):\n",
    "        return self.Actual_Qrs_Complex\n",
    "\n",
    "    def Fs(self):\n",
    "        return self.Fs\n",
    "\n",
    "    def Evaluation(self, detectors, predict_peaks, binary_classification, score_calculation):\n",
    "        for detector in detectors:\n",
    "            self.Evaluations.append(Evaluation(self,detector,predict_peaks, binary_classification, score_calculation).calculate())\n",
    "        return self.Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a function to split signals in smaller parts including the respecitve qrs complexes. `split_signal` returns an array of arrays where the inner arrays store the signals and the qrs complexes and the outer array stores the inner arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_signal(signal, fs, actual_qrs_complexes):\n",
    "    signal = np.array(signal)\n",
    "    actual_qrs_complexes = np.array(actual_qrs_complexes)\n",
    "    split = [[] for i in range(((len(signal)//(fs*segmentation_window_size)*2)-1))]\n",
    "\n",
    "    for split_signal_counter in range((len(signal)//(fs*segmentation_window_size)*2)-1):\n",
    "        min_index = split_signal_counter*(fs*segmentation_window_size//2)\n",
    "        max_index = split_signal_counter*(fs*segmentation_window_size//2)+fs*segmentation_window_size-1\n",
    "\n",
    "        split[split_signal_counter].append(signal[min_index:max_index])\n",
    "\n",
    "        min_counter = 0\n",
    "        max_counter = 0\n",
    "\n",
    "        for qrs_complex_counter in range(len(actual_qrs_complexes)):\n",
    "            if actual_qrs_complexes[qrs_complex_counter] < min_index:\n",
    "                min_counter += 1\n",
    "            if actual_qrs_complexes[qrs_complex_counter] < max_index:\n",
    "                max_counter += 1\n",
    "        split[split_signal_counter].append(actual_qrs_complexes[min_counter:max_counter]-min_index)\n",
    "\n",
    "    return split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Database Objects\n",
    "### Telehealth Database\n",
    "Create a `Database` object for `telehealth_environment_database` including all sub objects necessary to initialize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "telehealth_path = join(current_working_directory,'databases/telehealth')\n",
    "telehealth_files = [f for f in listdir(telehealth_path) if isfile(join(telehealth_path, f))]\n",
    "\n",
    "telehealth_fs = 500\n",
    "users = []\n",
    "recordings = []\n",
    "for file in telehealth_files:\n",
    "    recordingsegments = []\n",
    "    data = pandas.read_csv(join(telehealth_path, file),sep=\",\",header=None)\n",
    "    signal = np.array(data[0]).astype(float)\n",
    "    qrs_complex_indices = np.array(data[1]).astype(int)\n",
    "    actual_qrs_complexes = []\n",
    "    \n",
    "    for indexcounter in range(len(qrs_complex_indices)):\n",
    "        if qrs_complex_indices[indexcounter]:\n",
    "            actual_qrs_complexes.append(indexcounter)\n",
    "    \n",
    "    splits = split_signal(signal=signal,fs=telehealth_fs, actual_qrs_complexes=np.array(actual_qrs_complexes).astype(int))\n",
    "    \n",
    "    for split in splits:\n",
    "        recordingsegments.append(RecordingSegment(Signal=split[0], Actual_Qrs_Complex=split[1], Fs=telehealth_fs))\n",
    "    recordings.append(Recording(RecordingName=str(file),RecordingSegments = recordingsegments,WholeSignal=signal,WholeActual_Qrs_Complex=actual_qrs_complexes,Fs=telehealth_fs))\n",
    "users.append(User(UserName=\"default\",Recordings = recordings))   \n",
    "        \n",
    "telehealth_environment_database = Database(\n",
    "    Name=\"Telehealth Test Database\",\n",
    "    Users=users,\n",
    "    Fs=telehealth_fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic Database\n",
    "Some initial parameters for the generation of the synthetic signals. Here it is possible to choose diffent types of artificial noise and also choose whether the signal should be real or synthetic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---Initial parameters---\n",
    "rrLength = 50       # A desired ECG signal length (the number of RR intervals) \n",
    "APBrate = 0.10      # Rate of atrial premature beats (APB). A number between 0 and 0.5\n",
    "onlyRR = 0          # 1 - only RR intervals are generated, 0 - multilead ECG is generated\n",
    "\n",
    "medEpis = 15        # Median duration of an atrial fibrillation (AF) episode\n",
    "stayInAF = float(1-np.log(2)/medEpis)   # Probability to stay in AF state\n",
    "AFburden = 0.8      # AF burden. 0 - the entire signal is sinus rhythm (SR), 1 - the entire signal is AF\n",
    "\n",
    "noiseType = 4       # Type of noise. A number from 0 to 4. 0 - no noise added (noise RMS = 0 mV), \n",
    "                    # 1 - motion artefacts, 2 - electrode movement artefacts, 3 - baseline wander, \n",
    "                    # 4 - mixture of type 1, type 2 and type 3 noises\n",
    "noiseRMS = 0.02     # Noise level in milivolts \n",
    "\n",
    "realRRon = 1       # 1 - real RR series are used, 0 - synthetic\n",
    "realVAon = 1       # 1 - real ventricular activity is used, 0 - synthetic\n",
    "realAAon = 1       # 1 - real atrial activity is used, 0 - synthetic\n",
    "# Note: cannot select real atrial activity and synthetic ventricular activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a synthetic signal and safe it in `returndata`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_generator_path = eng.genpath('C:/Users/flori\\OneDrive\\Dokumente\\TU\\Bachelor Thesis\\Code\\Signal_generator')\n",
    "eng.addpath(signal_generator_path, nargout=0)\n",
    "\n",
    "returndata = eng.simPAF_ECG_generator(rrLength, realRRon, realVAon, realAAon, AFburden, stayInAF, APBrate, noiseType, noiseRMS, onlyRR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `Database` object for `synth_database` including all sub objects necessary to initialize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_fs = 500\n",
    "signal = np.transpose(np.array(returndata['multileadECG']))[:,0]\n",
    "actual_qrs_complexes = np.transpose(np.array(returndata['QRSindex']))[:,0].astype(int)\n",
    "\n",
    "splits = split_signal(signal=signal,fs=synth_fs,actual_qrs_complexes=actual_qrs_complexes)\n",
    "\n",
    "recordingsegments = []\n",
    "for split in splits:\n",
    "    recordingsegments.append(RecordingSegment(Signal=split[0],Actual_Qrs_Complex=split[1],Fs=synth_fs))\n",
    "recordings = [Recording(\"default\",RecordingSegments=recordingsegments, WholeSignal=signal,WholeActual_Qrs_Complex=actual_qrs_complexes,Fs=synth_fs)]\n",
    "users = [User(UserName=\"default\",Recordings=recordings)]\n",
    "\n",
    "synth_database = Database(\n",
    "    Name=\"Synthetic data\", \n",
    "    Users=users,\n",
    "    Fs=synth_fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WFDB Test Database\n",
    "Create a `Database` object for `wfdb_test_database` including all sub objects necessary to initialize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "wfdb_fs = wfdb.rdrecord('sample-data/100', sampfrom=0, sampto=10000, channels=[0]).fs\n",
    "signal = np.array(wfdb.rdrecord('sample-data/100', sampfrom=0, sampto=10000, channels=[0]).p_signal[:,0])\n",
    "actual_qrs_complexes = np.array(wfdb.rdann('sample-data/100','atr', sampfrom=0, sampto=10000).sample[1:]).astype(int)\n",
    "\n",
    "splits = split_signal(signal=signal, fs=wfdb_fs, actual_qrs_complexes=actual_qrs_complexes)\n",
    "\n",
    "recordingsegments = []\n",
    "for split in splits:\n",
    "    recordingsegments.append(RecordingSegment(Signal=split[0],Actual_Qrs_Complex=split[1],Fs=wfdb_fs))\n",
    "recordings = [Recording(\"default\",RecordingSegments=recordingsegments, WholeSignal=signal,WholeActual_Qrs_Complex=actual_qrs_complexes,Fs=wfdb_fs)]\n",
    "users = [User(UserName=\"default\",Recordings=recordings)]\n",
    "\n",
    "wfdb_test_database = Database(\n",
    "    Name=\"WFDB Test Database\",\n",
    "    Users=users,\n",
    "    Fs=wfdb_fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Detector Objects\n",
    "Create `Detector` objects for detectors from different locations in the standaradized format.\n",
    "\n",
    "Create `gqrs_detector` object. This detector stems from the wfdb toolbox. More information can be found online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "gqrs_detector = Detector(name=\"GQRS\", short_name=\"gqrs\", algorithm=processing.qrs.gqrs_detect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `jqrs_detector` object. This detector is written in MATLAB and also executed via the MATLAB engine. Therefore a function has been written to get it into the right format. More information can be found in the respective file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "jqrs_algo_path = eng.genpath('C:/Users/flori\\OneDrive\\Dokumente\\TU\\Bachelor Thesis\\Code\\Playground\\detectors\\jqrs')\n",
    "eng.addpath(jqrs_algo_path, nargout=0)\n",
    "\n",
    "def run_jqrs_detector(signal, fs):\n",
    "    threshold = 0.6 # energy threshold of the detector in au, default = 0.6\n",
    "    ref_period = 0.250 # refractory period in sec between two R-peaks in ms, default = 0.250\n",
    "    newsignal = [[i] for i in signal]\n",
    "    return np.array(eng.qrs_detect2(matlab.double(newsignal), threshold, ref_period, matlab.double(fs)))[0].astype(int)\n",
    "\n",
    "jqrs_detector = Detector(name=\"JQRS\", short_name=\"jqrs\", algorithm=run_jqrs_detector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `visgraph_detector` object. For this detector a Python implementation is used. More information can be found in the respecitve file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_visgraph_detector(signal, fs):\n",
    "    beta = 0.55 # beta, default = 0.55\n",
    "    gamma = 0.5 # gamm, default = 0.5\n",
    "    lowcut = 4 # lowcut, default = 4\n",
    "    R_peaks, weights, weighted_signal = VisGraphDetector(fs).visgraphdetect(signal, beta=beta, gamma=gamma, lowcut=lowcut, M = 2*fs)\n",
    "    return R_peaks\n",
    "\n",
    "visgraph_detector = Detector(name=\"VisGraphDetector\", short_name=\"visgraph\", algorithm=run_visgraph_detector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `rpeakdetect_detector` object. This detector is written in MATLAB and also executed via the MATLAB engine. Therefore a function has been written to get it into the right format. More information can be found in the respective file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpeakdetect_path = eng.genpath('C:/Users/flori\\OneDrive\\Dokumente\\TU\\Bachelor Thesis\\Code\\Playground\\detectors')\n",
    "eng.addpath(rpeakdetect_path, nargout=0)\n",
    "\n",
    "def run_rpeakdetect_detector(signal, fs):\n",
    "    threshhold = 0.2 # default = 0.2\n",
    "    testmode = 0 # default = 0\n",
    "    newsignal = [[i] for i in signal]\n",
    "    return np.array(eng.rpeakdetect(matlab.double(newsignal), matlab.double(fs),threshhold,testmode)['R_index'])[0].astype(int)\n",
    "\n",
    "rpeakdetect_detector = Detector(name=\"rpeakdetect\", short_name=\"rpeak\", algorithm=run_rpeakdetect_detector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `r_deco_detector` object. This detector is written in MATLAB and also executed via the MATLAB engine. Therefore a function has been written to get it into the right format. More information can be found in the respective file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_deco_path = eng.genpath('C:/Users/flori\\OneDrive\\Dokumente\\TU\\Bachelor Thesis\\Code\\Playground\\detectors/r_deco')\n",
    "eng.addpath(r_deco_path, nargout=0)\n",
    "\n",
    "def run_r_deco_detector(signal, fs):\n",
    "    envelope_size = 300.0 # envelope size in ms, default = 300.0\n",
    "    average_heart_rate = 100.0 # average heart rate in bpm, default = 100.0\n",
    "    post_processing = 1.0 # post processing where 1.0 means yes, default = 1.0\n",
    "    ectopic_removal = 0.0 # ectopic removal where 1.0 means yes, default = 0.0\n",
    "    inverted_signal = 0.0 # inverted signal where 1.0 means yes, default = 0.0\n",
    "    parameters_check = 0.0 # parameters check in UI where 1.0 means yes, default = 0.0\n",
    "    newsignal = [[i] for i in signal]\n",
    "    return np.array(eng.peak_detection([envelope_size,average_heart_rate,post_processing,ectopic_removal,inverted_signal],matlab.double(newsignal), matlab.double(fs),parameters_check)).astype(int)[0][0]\n",
    "\n",
    "r_deco_detector = Detector(name=\"r_deco\", short_name=\"rdeco\", algorithm=run_r_deco_detector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `unsw_detector` object. This detector is written in MATLAB and also executed via the MATLAB engine. Therefore a function has been written to get it into the right format. More information can be found in the respective file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsw_path = eng.genpath('C:/Users/flori\\OneDrive\\Dokumente\\TU\\Bachelor Thesis\\Code\\Databases\\Telehealth')\n",
    "eng.addpath(unsw_path, nargout=0)\n",
    "\n",
    "def run_unsw_detector(signal, fs):\n",
    "    mask = [] # mask could be implemented later if wanted\n",
    "    plotting = 0 # 1.0 for ploting intermediate signals, 0.0 for no plotting, default = 0.0\n",
    "    newsignal = [[i] for i in signal]\n",
    "    return np.array(eng.UNSW_QRSDetector(matlab.double(newsignal), matlab.double(fs),matlab.double(mask),matlab.double(plotting))).astype(int)[0]\n",
    "\n",
    "unsw_detector = Detector(name=\"UNSW_QRSDetector\", short_name=\"unsw\", algorithm=run_unsw_detector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create functions to get the detectors from the `ecgdetectors` package into the right standard format. Additionally they are safed into their own objects. More information about the package can be found online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_two_average_detector(signal, fs):\n",
    "    return Detectors(fs).two_average_detector(unfiltered_ecg=signal)\n",
    "\n",
    "two_average_detector = Detector(name=\"Elgendi et al (Two average)\", short_name=\"two_avg\", algorithm=run_two_average_detector)\n",
    "\n",
    "def run_matched_filter_detector(signal, fs):\n",
    "    return Detectors(fs).matched_filter_detector(unfiltered_ecg=signal)\n",
    "\n",
    "matched_filter_detector = Detector(name=\"Matched filter\", short_name=\"match_fil\", algorithm=run_matched_filter_detector)\n",
    "\n",
    "def run_swt_detector(signal, fs):\n",
    "    return Detectors(fs).swt_detector(unfiltered_ecg=signal)\n",
    "\n",
    "swt_detector = Detector(name=\"Kalidas & Tamil (Wavelet transform)\", short_name=\"swt\", algorithm=run_swt_detector)\n",
    "\n",
    "def run_engzee_detector(signal, fs):\n",
    "    return Detectors(fs).engzee_detector(unfiltered_ecg=signal)\n",
    "\n",
    "engzee_detector = Detector(name=\"Engzee\", short_name=\"engz\", algorithm=run_engzee_detector)\n",
    "\n",
    "def run_christov_detector(signal, fs):\n",
    "    return Detectors(fs).christov_detector(unfiltered_ecg=signal)\n",
    "\n",
    "christov_detector = Detector(name=\"Christov\", short_name=\"christ\", algorithm=run_christov_detector)\n",
    "\n",
    "def run_hamilton_detector(signal, fs):\n",
    "    return Detectors(fs).hamilton_detector(unfiltered_ecg=signal)\n",
    "\n",
    "hamilton_detector = Detector(name=\"Hamilton\", short_name=\"hamilt\", algorithm=run_hamilton_detector)\n",
    "\n",
    "def run_pan_tompkins_detector(signal, fs):\n",
    "    return Detectors(fs).pan_tompkins_detector(unfiltered_ecg=signal)\n",
    "\n",
    "pan_tompkins_detector = Detector(name=\"Pan Tompkins\", short_name=\"pan_tomp\", algorithm=run_pan_tompkins_detector)\n",
    "\n",
    "def run_wqrs_detector(signal, fs):\n",
    "    return Detectors(fs).wqrs_detector(unfiltered_ecg=signal)\n",
    "\n",
    "wqrs_detector = Detector(name=\"WQRS\", short_name=\"wqrs\", algorithm=run_wqrs_detector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Databases and Detectors\n",
    "Create arrays to safe the `detectors` and `databases`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "databases = []\n",
    "detectors = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add data from different databases to `databases`. By commenting or uncommenting a database here, you can decide whether it should be used in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "databases.append(synth_database)\n",
    "#databases.append(wfdb_test_database)\n",
    "#databases.append(telehealth_environment_database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add detectors to the `detectors`. By commenting or uncommenting a detector here, you can decide whether it should be used in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "detectors.append(gqrs_detector)\n",
    "detectors.append(jqrs_detector)\n",
    "detectors.append(visgraph_detector)\n",
    "detectors.append(rpeakdetect_detector)\n",
    "detectors.append(r_deco_detector)\n",
    "#detectors.append(unsw_detector)\n",
    "detectors.append(two_average_detector)\n",
    "detectors.append(matched_filter_detector)\n",
    "detectors.append(swt_detector)\n",
    "#detectors.append(engzee_detector)\n",
    "detectors.append(christov_detector)\n",
    "detectors.append(hamilton_detector)\n",
    "detectors.append(pan_tompkins_detector)\n",
    "detectors.append(wqrs_detector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_peaks(segment, detector):\n",
    "\n",
    "    if isinstance(segment, RecordingSegment):\n",
    "        signal = segment.Signal\n",
    "        fs = segment.Fs\n",
    "\n",
    "    elif isinstance(segment, Recording):\n",
    "        signal = segment.WholeSignal\n",
    "        fs = segment.Fs\n",
    "\n",
    "    else:\n",
    "        raise Exception('You have to input either a RecordingSegment or a Recording as the segment.')\n",
    "        \n",
    "    \n",
    "    if detector.short_name == \"match_fil\" and (fs != 250 and fs != 360):\n",
    "        #print(detector.short_name, \"could not run because the sample rate is wrong and was skipped\")\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        predicted_peaks = detector.predicted_qrs_compelx(signal=signal, fs=fs)\n",
    "    except IndexError:\n",
    "        print(detector.short_name, \"failed due to an index error and was skipped\")\n",
    "        return []\n",
    "    \n",
    "    return predicted_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_classification(segment, predicted_peaks):\n",
    "\n",
    "    if isinstance(segment, RecordingSegment):\n",
    "        signal = segment.Signal\n",
    "        fs = segment.Fs\n",
    "        actual_peaks = segment.Actual_Qrs_Complex\n",
    "\n",
    "    elif isinstance(segment, Recording):\n",
    "        signal = segment.WholeSignal\n",
    "        fs = segment.Fs\n",
    "        actual_peaks = segment.WholeActual_Qrs_Complex\n",
    "\n",
    "    else:\n",
    "        raise Exception('You have to input either a RecordingSegment or a Recording as the segment.')\n",
    "\n",
    "    pp = len(predicted_peaks)\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    \n",
    "    actual_peaks_iter = actual_peaks\n",
    "\n",
    "    for predicted_peak in predicted_peaks:\n",
    "        tpdetect = 1\n",
    "        for i in range(len(actual_peaks_iter)):\n",
    "            if predicted_peak >= (actual_peaks_iter[i] - tolerance_window_size) and predicted_peak <= (actual_peaks_iter[i] + tolerance_window_size):\n",
    "                tp+=1\n",
    "                tpdetect = 0\n",
    "                actual_peaks_iter = np.delete(actual_peaks_iter, i)\n",
    "                break\n",
    "        if tpdetect:\n",
    "            fp+=1\n",
    "\n",
    "    for actualpeak in actual_peaks_iter:\n",
    "        fn+=1\n",
    "\n",
    "    return pp, tp, fp, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_calculation(tp, fp, fn):\n",
    "    try:\n",
    "        sensitivity = tp / (tp+fn)\n",
    "    except ZeroDivisionError:\n",
    "        sensitivity = 0\n",
    "    try:\n",
    "        positive_predictivity = tp / (tp+fp)\n",
    "    except ZeroDivisionError:\n",
    "        positive_predictivity = 0\n",
    "    try:    \n",
    "        f1_score = tp / (tp+.5*(fp+fn))\n",
    "    except ZeroDivisionError:\n",
    "        f1_score = 0\n",
    "    return sensitivity, positive_predictivity, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict QRS Complexes\n",
    "All algorithms are run and the resulting QRS complexes are saved in vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic data\n",
      "default\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\flori\\OneDrive\\Dokumente\\TU\\Bachelor Thesis\\Code\\Playground\\playground.ipynb Zelle 56\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/flori/OneDrive/Dokumente/TU/Bachelor%20Thesis/Code/Playground/playground.ipynb#X63sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m evaluations \u001b[39m=\u001b[39m recordingsegment\u001b[39m.\u001b[39mEvaluation(detectors, predict_peaks, binary_classification, score_calculation)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/flori/OneDrive/Dokumente/TU/Bachelor%20Thesis/Code/Playground/playground.ipynb#X63sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(evaluations)):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/flori/OneDrive/Dokumente/TU/Bachelor%20Thesis/Code/Playground/playground.ipynb#X63sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39mif\u001b[39;00m evaluations[i]\u001b[39m.\u001b[39msensitivity \u001b[39m<\u001b[39m sensitivity[i]: sensitivity[i] \u001b[39m=\u001b[39m evaluations[i]\u001b[39m.\u001b[39msensitivity\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/flori/OneDrive/Dokumente/TU/Bachelor%20Thesis/Code/Playground/playground.ipynb#X63sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39mif\u001b[39;00m evaluations[i]\u001b[39m.\u001b[39mpositive_predictivity \u001b[39m<\u001b[39m positive_predictivity[i]: positive_predictivity[i] \u001b[39m=\u001b[39m evaluations[i]\u001b[39m.\u001b[39mpositive_predictivity\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/flori/OneDrive/Dokumente/TU/Bachelor%20Thesis/Code/Playground/playground.ipynb#X63sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mif\u001b[39;00m evaluations[i]\u001b[39m.\u001b[39mf1_score \u001b[39m<\u001b[39m f1_score[i]: f1_score[i] \u001b[39m=\u001b[39m evaluations[i]\u001b[39m.\u001b[39mf1_score\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for database in databases:\n",
    "    print(database.Name)\n",
    "    sensitivity = [1 for i in range(len(detectors))]\n",
    "    positive_predictivity = [1 for i in range(len(detectors))]\n",
    "    f1_score = [1 for i in range(len(detectors))]\n",
    "    for user in database.Users:\n",
    "        for recording in user.Recordings:\n",
    "            print(recording.RecordingName)\n",
    "            for recordingsegment in recording.RecordingSegments:\n",
    "                evaluations = recordingsegment.Evaluation(detectors, predict_peaks, binary_classification, score_calculation)\n",
    "                for i in range(len(evaluations)):\n",
    "                    if evaluations[i].sensitivity < sensitivity[i]: sensitivity[i] = evaluations[i].sensitivity\n",
    "                    if evaluations[i].positive_predictivity < positive_predictivity[i]: positive_predictivity[i] = evaluations[i].positive_predictivity\n",
    "                    if evaluations[i].f1_score < f1_score[i]: f1_score[i] = evaluations[i].f1_score\n",
    "\n",
    "    data = [np.around(sensitivity,decimals=2), np.around(positive_predictivity,decimals=2),np.around(f1_score,decimals=2)]\n",
    "    rows = [\"sensitiv\", \"pos pred\", \"f1 score\"]\n",
    "    columns = [detector.short_name for detector in detectors]\n",
    "\n",
    "    print(pandas.DataFrame(data, rows, columns))\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
